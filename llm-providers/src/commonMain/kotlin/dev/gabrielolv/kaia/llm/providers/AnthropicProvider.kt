package dev.gabrielolv.kaia.llm.providers

import dev.gabrielolv.kaia.llm.LLMMessage
import dev.gabrielolv.kaia.llm.LLMOptions
import dev.gabrielolv.kaia.llm.LLMProvider
import dev.gabrielolv.kaia.utils.createHttpEngine
import io.ktor.client.*
import io.ktor.client.call.*
import io.ktor.client.plugins.contentnegotiation.*
import io.ktor.client.request.*
import io.ktor.http.*
import io.ktor.serialization.kotlinx.json.*
import kotlinx.coroutines.flow.Flow
import kotlinx.coroutines.flow.flow
import kotlinx.serialization.ExperimentalSerializationApi
import kotlinx.serialization.Serializable
import kotlinx.serialization.json.Json
import kotlinx.serialization.json.JsonNamingStrategy
import kotlinx.serialization.json.encodeToJsonElement

internal class AnthropicProvider(
    private val apiKey: String,
    private val baseUrl: String,
    private val model: String
) : LLMProvider {
    @OptIn(ExperimentalSerializationApi::class)
    val json = Json {
        ignoreUnknownKeys = true
        explicitNulls = false
        encodeDefaults = true
        isLenient = true
        namingStrategy = JsonNamingStrategy.SnakeCase
    }
    val httpClient = HttpClient(createHttpEngine()) {
        install(ContentNegotiation) {
            json(json)
        }
        expectSuccess = true
    }

    @Serializable
    private data class AnthropicMessage(
        val role: String,
        val content: List<AnthropicContent>
    )

    @Serializable
    private data class AnthropicContent(
        val type: String = "text",
        val text: String? = null
    )

    @Serializable
    private data class AnthropicRequest(
        val model: String,
        val messages: List<AnthropicMessage>,
        val max_tokens: Int? = null,
        val temperature: Double = 0.7,
        val system: String? = null,
        val stop_sequences: List<String>? = null
    )

    @Serializable
    private data class AnthropicResponse(
        val content: List<AnthropicContent>,
        val model: String,
        val role: String
    )

    private fun LLMMessage.toAnthropicMessage(): AnthropicMessage? = when (this) {
        is LLMMessage.UserMessage -> AnthropicMessage(
            role = "user",
            content = listOf(AnthropicContent(text = content))
        )
        is LLMMessage.AssistantMessage -> AnthropicMessage(
            role = "assistant",
            content = listOf(AnthropicContent(text = content))
        )
        is LLMMessage.SystemMessage -> null // System messages are handled separately
        is LLMMessage.ToolCallMessage -> null // Tool calls not supported in basic Anthropic API
        is LLMMessage.ToolResponseMessage -> null // Tool responses not supported in basic Anthropic API
    }

    override fun generate(
        messages: List<LLMMessage>,
        options: LLMOptions
    ): Flow<LLMMessage> = flow {
        // Prepare messages for the API call
        val apiMessages = mutableListOf<AnthropicMessage>()

        // Convert and add conversation messages
        val conversationMessages = messages.filterNot { it is LLMMessage.SystemMessage }
        conversationMessages.mapNotNull { it.toAnthropicMessage() }.forEach { apiMessages.add(it) }

        // Ensure there's at least one message
        if (apiMessages.isEmpty()) {
            emit(LLMMessage.SystemMessage("Error: No valid messages found to send to Anthropic API after filtering."))
            return@flow
        }

        // Extract system message
        val systemPrompt = options.systemPrompt ?: 
            messages.filterIsInstance<LLMMessage.SystemMessage>().lastOrNull()?.content

        val request = AnthropicRequest(
            model = model,
            messages = apiMessages,
            max_tokens = options.maxTokens ?: 4096,
            temperature = options.temperature,
            system = systemPrompt,
            stop_sequences = options.stopSequences.takeIf { it.isNotEmpty() }
        )

        val response: AnthropicResponse = try {
            httpClient.post("$baseUrl/messages") {
                contentType(ContentType.Application.Json)
                header("x-api-key", apiKey)
                header("anthropic-version", "2023-06-01")
                setBody(request)
            }.body()
        } catch (e: Exception) {
            // Handle API errors gracefully
            emit(LLMMessage.SystemMessage("Error calling Anthropic API: ${e.message}"))
            return@flow
        }

        // Extract content from response
        val content = response.content.firstOrNull { it.type == "text" }?.text ?: ""
        val rawResponse = Json.encodeToJsonElement(response)

        // Emit the assistant message generated by the API
        emit(LLMMessage.AssistantMessage(content, rawResponse))
    }
}
